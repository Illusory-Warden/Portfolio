<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>IntelliRead - PDF Intelligence Platform - Rushi Daulatkar</title>
    <meta
      name="description"
      content="AI-powered PDF intelligence platform for transforming enterprise documents into searchable, structured knowledge with semantic search and multi-provider AI chat"
    />
    <style>
      /* RESET & BASE STYLES */
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      /* ROOT VARIABLES FOR THEMING */
      :root {
        --bg-primary: #ffffff;
        --bg-secondary: #fafafa;
        --bg-tertiary: #f5f5f5;
        --bg-placeholder: #f9f9f9;
        --text-primary: #000000;
        --text-secondary: #666666;
        --border-primary: #000000;
        --border-secondary: #cccccc;
        --border-tertiary: #dddddd;
        --link-color: #0066cc;
        --link-hover: #003d7a;
        --shadow-color: rgba(0, 0, 0, 0.1);
      }

      /* DARK MODE VARIABLES */
      [data-theme="dark"] {
        --bg-primary: #1a1a1a;
        --bg-secondary: #2d2d2d;
        --bg-tertiary: #383838;
        --bg-placeholder: #2a2a2a;
        --text-primary: #e0e0e0;
        --text-secondary: #a0a0a0;
        --border-primary: #ffffff;
        --border-secondary: #404040;
        --border-tertiary: #505050;
        --link-color: #66b3ff;
        --link-hover: #99ccff;
        --shadow-color: rgba(255, 255, 255, 0.1);
      }

      body {
        font-family: Arial, sans-serif;
        line-height: 1.6;
        padding-top: 60px;
        background: var(--bg-primary);
        color: var(--text-primary);
        transition: background-color 0.3s ease, color 0.3s ease;
      }

      /* NAVIGATION BAR */
      .navbar {
        position: fixed;
        top: 0;
        left: 0;
        right: 0;
        background: var(--bg-primary);
        border-bottom: 2px solid var(--border-primary);
        padding: 15px 20px;
        display: flex;
        justify-content: space-between;
        align-items: center;
        z-index: 1000;
        transition: background-color 0.3s ease, border-color 0.3s ease;
        box-shadow: 0 2px 4px var(--shadow-color);
      }

      .navbar a {
        color: var(--text-primary);
        text-decoration: none;
        font-weight: bold;
        font-size: 18px;
        transition: color 0.3s ease;
      }

      .navbar a:hover {
        color: var(--link-color);
      }

      #themeToggle {
        padding: 8px 14px;
        background: var(--bg-primary);
        border: 2px solid var(--border-primary);
        cursor: pointer;
        font-size: 18px;
        display: flex;
        align-items: center;
        justify-content: center;
        transition: all 0.3s ease;
      }

      #themeToggle:hover {
        background: var(--border-primary);
        color: var(--bg-primary);
        transform: translateY(-2px);
      }

      /* MAIN CONTENT */
      .content {
        padding: 20px;
        max-width: 900px;
        margin: 0 auto;
      }

      /* CONTAINER BOXES */
      .container {
        border: 1px solid var(--border-secondary);
        padding: 20px;
        margin: 20px 0;
        background: var(--bg-primary);
        opacity: 0;
        transform: translateY(20px);
        transition: opacity 0.6s ease, transform 0.6s ease,
          background-color 0.3s ease, border-color 0.3s ease,
          box-shadow 0.3s ease;
        box-shadow: 0 2px 4px var(--shadow-color);
      }

      .container:hover {
        transform: translateY(-5px);
        box-shadow: 0 8px 16px var(--shadow-color);
      }

      .container.visible {
        opacity: 1;
        transform: translateY(0);
      }

      .container.visible:hover {
        transform: translateY(-5px);
      }

      /* HEADER */
      .page-header {
        border: 2px solid var(--border-primary);
        padding: 20px;
        margin-bottom: 30px;
        background: var(--bg-primary);
        transition: all 0.3s ease;
        box-shadow: 0 2px 4px var(--shadow-color);
      }

      .page-header:hover {
        transform: translateY(-3px);
        box-shadow: 0 6px 12px var(--shadow-color);
      }

      .page-header h1 {
        font-size: 28px;
        margin-bottom: 10px;
        color: var(--text-primary);
      }

      .back-link {
        display: inline-block;
        padding: 8px 16px;
        border: 1px solid var(--border-primary);
        background: var(--bg-primary);
        color: var(--text-primary);
        text-decoration: none;
        transition: all 0.3s ease;
      }

      .back-link:hover {
        background: var(--border-primary);
        color: var(--bg-primary);
        transform: translateY(-2px);
        box-shadow: 0 4px 8px var(--shadow-color);
        text-decoration: none;
      }

      /* SECTION HEADINGS */
      h2 {
        font-size: 22px;
        margin-bottom: 15px;
        padding-bottom: 8px;
        border-bottom: 2px solid var(--border-primary);
        color: var(--text-primary);
      }

      h3 {
        font-size: 18px;
        margin: 15px 0 10px 0;
        color: var(--text-primary);
      }

      /* LINKS */
      a {
        color: var(--link-color);
        text-decoration: none;
        transition: color 0.3s ease;
      }

      a:hover {
        color: var(--link-hover);
        text-decoration: underline;
      }

      /* LISTS */
      ul {
        margin-left: 20px;
        margin-top: 10px;
      }

      li {
        margin: 8px 0;
        color: var(--text-primary);
      }

      /* SUBSECTIONS */
      .subsection {
        border: 1px solid var(--border-tertiary);
        padding: 15px;
        margin: 15px 0;
        background: var(--bg-secondary);
        transition: all 0.3s ease;
        box-shadow: 0 1px 3px var(--shadow-color);
      }

      .subsection:hover {
        transform: translateX(5px);
        box-shadow: 0 4px 8px var(--shadow-color);
      }

      .subsection strong {
        display: block;
        margin-bottom: 8px;
        color: var(--text-primary);
      }

      /* IMAGE PLACEHOLDERS */
      .image-placeholder {
        border: 2px dashed var(--border-secondary);
        padding: 40px;
        margin: 20px 0;
        text-align: center;
        background: var(--bg-placeholder);
        color: var(--text-secondary);
        transition: all 0.3s ease;
      }

      .image-placeholder:hover {
        border-color: var(--border-primary);
        transform: scale(1.02);
      }

      img {
        max-width: 100%;
        height: auto;
        border: 1px solid var(--border-secondary);
        margin: 20px 0;
        transition: all 0.3s ease;
      }

      img:hover {
        transform: scale(1.02);
        box-shadow: 0 4px 8px var(--shadow-color);
      }

      .image-caption {
        font-style: italic;
        margin-top: 5px;
        color: var(--text-secondary);
      }

      /* PROJECT INFO BOX */
      .info-box {
        border: 2px solid var(--border-primary);
        padding: 15px;
        margin: 20px 0;
        background: var(--bg-tertiary);
        transition: all 0.3s ease;
      }

      .info-box p {
        margin: 5px 0;
        color: var(--text-primary);
      }

      /* CHALLENGE BOXES */
      .challenge-box {
        border-left: 4px solid var(--border-primary);
        padding: 15px;
        margin: 20px 0;
        background: var(--bg-secondary);
        transition: all 0.3s ease;
        box-shadow: 0 1px 3px var(--shadow-color);
      }

      .challenge-box:hover {
        transform: translateX(5px);
        box-shadow: 0 4px 8px var(--shadow-color);
      }

      /* LINKS SECTION */
      .links-section {
        border: 2px solid var(--border-primary);
        padding: 20px;
        margin: 30px 0;
        text-align: center;
        background: var(--bg-primary);
        transition: all 0.3s ease;
        box-shadow: 0 2px 4px var(--shadow-color);
      }

      .links-section:hover {
        transform: translateY(-3px);
        box-shadow: 0 6px 12px var(--shadow-color);
      }

      .links-section a {
        display: inline-block;
        margin: 5px 10px;
        padding: 10px 20px;
        border: 1px solid var(--border-primary);
        background: var(--border-primary);
        color: var(--bg-primary);
        text-decoration: none;
        transition: all 0.3s ease;
      }

      .links-section a:hover {
        background: var(--bg-primary);
        color: var(--border-primary);
        transform: translateY(-2px);
        box-shadow: 0 4px 8px var(--shadow-color);
      }

      /* GO TO TOP BUTTON */
      #goTopBtn {
        position: fixed;
        bottom: 20px;
        left: 20px;
        display: none;
        padding: 12px 18px;
        background: var(--border-primary);
        color: var(--bg-primary);
        border: 2px solid var(--border-primary);
        cursor: pointer;
        font-weight: bold;
        transition: all 0.3s ease;
        box-shadow: 0 4px 8px var(--shadow-color);
        z-index: 999;
      }

      #goTopBtn:hover {
        transform: translateY(-3px);
        box-shadow: 0 6px 12px var(--shadow-color);
      }

      /* RESPONSIVE */
      @media (max-width: 600px) {
        body {
          padding-top: 60px;
        }

        .content {
          padding: 10px;
        }

        .container {
          padding: 15px;
        }

        #themeToggle {
          padding: 6px 10px;
          font-size: 16px;
        }

        .navbar {
          padding: 12px 15px;
        }

        .navbar a {
          font-size: 16px;
        }
      }
    </style>
  </head>
  <body>
    <!-- NAVIGATION BAR -->
    <nav class="navbar">
      <a href="index.html">Home</a>
      <button
        id="themeToggle"
        onclick="toggleTheme()"
        aria-label="Toggle dark mode"
      >
        <span id="themeIcon">üåô</span>
      </button>
    </nav>

    <!-- MAIN CONTENT -->
    <div class="content">
      <!-- PAGE HEADER -->
      <div class="page-header">
        <h1>IntelliRead ‚Äì PDF Intelligence Platform</h1>
        <p><a href="index.html" class="back-link">‚Üê Back to Portfolio</a></p>
      </div>

      <!-- PROJECT OVERVIEW -->
      <section class="container">
        <div class="info-box">
          <p><strong>Program:</strong> Intel Unnati Industrial Training (Jan 2025)</p>
          <p><strong>Duration:</strong> Jan 2025</p>
          <p>
            <strong>Technologies:</strong> React, TypeScript, Vite, PDF.js, IndexedDB, Groq AI, Google Gemini, Perplexity, Anthropic Claude, Tailwind CSS, shadcn/ui, idb
          </p>
          <p>
            <strong>Category:</strong> AI-Powered Document Intelligence, Enterprise Software, Knowledge Management
          </p>
        </div>
      </section>

      <!-- DESCRIPTION -->
      <section class="container">
        <h2>Description</h2>
        <p>
          IntelliRead is a local-first, browser-only PDF intelligence platform developed as part of the Intel Unnati Industrial Training program. It transforms enterprise PDFs into searchable, structured knowledge using AI-powered analysis, eliminating the need for backend servers or external databases.
        </p>
        <p style="margin-top: 15px">
          Organizations manage thousands of PDFs‚Äîmanuals, reports, policies, research papers‚Äîbut finding specific information across these documents is time-consuming. IntelliRead solves this by making PDFs queryable: it preserves document structure, extracts tables, analyzes images with AI, and enables semantic search with natural language Q&A powered by multiple AI providers.
        </p>
        <p style="margin-top: 15px">
          Built with 100% client-side processing using IndexedDB for local storage, IntelliRead ensures complete data privacy‚Äîyour documents never leave your device. All PDF parsing, text extraction, chunking, and indexing happens in the browser, with AI providers called only for image descriptions and answering questions.
        </p>
      </section>

      <!-- SCREENSHOTS -->
      <section class="container">
        <h2>Screenshots</h2>
        
        <img src="images/intelliread-screenshot-1.png" alt="IntelliRead Main Interface" />
        <p class="image-caption">Main interface showing document upload and processing</p>

        <img src="images/intelliread-screenshot-2.png" alt="PDF Document Viewer" />
        <p class="image-caption">Document viewer with sections, tables, and image tabs</p>

        <img src="images/intelliread-screenshot-3.png" alt="AI Chat Interface" />
        <p class="image-caption">AI-powered Q&A interface with cited answers and page references</p>

        <img src="images/intelliread-screenshot-4.png" alt="API Settings Configuration" />
        <p class="image-caption">API configuration modal for Groq, Gemini, Perplexity, and Anthropic</p>

        <img src="images/intelliread-screenshot-5.png" alt="Document Processing Pipeline" />
        <p class="image-caption">Real-time processing progress with stage indicators</p>
      </section>

      <!-- KEY FEATURES -->
      <section class="container">
        <h2>Key Features</h2>

        <h3>Intelligent Document Processing</h3>
        <ul>
          <li>
            <strong>Structure Preservation:</strong> Maintains headings, sections, chapters, and page numbers from the original PDF
          </li>
          <li>
            <strong>Smart Chunking:</strong> Splits content at natural boundaries (sentences, paragraphs, sections) without breaking words mid-sentence
          </li>
          <li>
            <strong>Table Extraction:</strong> Detects and extracts tables with row/column integrity preserved
          </li>
          <li>
            <strong>Image Analysis:</strong> AI-generated descriptions make visual content (charts, diagrams, scanned pages) fully searchable
          </li>
          <li>
            <strong>Multi-Format Support:</strong> Text-based PDFs, mixed PDFs with images, image-only PDFs (scanned documents), and chart-heavy documents
          </li>
        </ul>

        <h3>AI-Powered Search & Q&A</h3>
        <ul>
          <li>
            <strong>Semantic Search:</strong> Find content by meaning, not just exact keywords
          </li>
          <li>
            <strong>Multi-Provider AI:</strong> Choose between Groq (fast responses), Perplexity (web-grounded), Anthropic Claude (complex reasoning), or Google Gemini (image analysis)
          </li>
          <li>
            <strong>Cited Answers:</strong> AI responses include page references for verification and traceability
          </li>
          <li>
            <strong>Document-Scoped:</strong> Answers are grounded in your uploaded documents, not general knowledge
          </li>
          <li>
            <strong>Chat Export:</strong> Download conversation history as PDF for documentation
          </li>
        </ul>

        <h3>Privacy-First Architecture</h3>
        <ul>
          <li>
            <strong>100% Client-Side:</strong> All processing happens in your browser‚Äîno server uploads, no cloud storage
          </li>
          <li>
            <strong>IndexedDB Storage:</strong> Documents persist locally with browser-managed encryption
          </li>
          <li>
            <strong>API Calls Only When Needed:</strong> AI providers are called only for image descriptions (Gemini) and answering questions (Groq/Perplexity/Anthropic)
          </li>
          <li>
            <strong>User-Controlled Keys:</strong> You provide and manage your own API keys‚Äîno data shared with third parties
          </li>
        </ul>
      </section>

      <!-- SUPPORTED PDF TYPES -->
      <section class="container">
        <h2>Supported PDF Types</h2>

        <div class="subsection">
          <strong>Text-based PDFs</strong>
          <p>Standard PDFs with selectable text. Direct text extraction via PDF.js with full section and table detection.</p>
        </div>

        <div class="subsection">
          <strong>Mixed PDFs</strong>
          <p>Documents combining text and images. Hybrid extraction with AI image analysis for charts and diagrams embedded in text content.</p>
        </div>

        <div class="subsection">
          <strong>Image-only PDFs</strong>
          <p>Scanned documents or photo PDFs. Full page rendering to PNG with Gemini AI descriptions for searchable content.</p>
        </div>

        <div class="subsection">
          <strong>Chart-heavy PDFs</strong>
          <p>Data visualizations and technical diagrams. AI-powered chart interpretation with data point extraction.</p>
        </div>
      </section>

      <!-- TECHNICAL IMPLEMENTATION -->
      <section class="container">
        <h2>Technical Implementation</h2>

        <h3>System Architecture</h3>
        <ul>
          <li>
            <strong>Frontend Framework:</strong> React 18 with TypeScript for type safety and modern component architecture
          </li>
          <li>
            <strong>Build Tool:</strong> Vite for fast development and optimized production builds
          </li>
          <li>
            <strong>UI Components:</strong> shadcn/ui with Tailwind CSS for consistent, responsive design
          </li>
          <li>
            <strong>PDF Processing:</strong> PDF.js (client-side) for text extraction, page rendering, and image detection
          </li>
          <li>
            <strong>Storage:</strong> IndexedDB via idb library for efficient document, chunk, and chat history storage
          </li>
          <li>
            <strong>AI Providers:</strong> Groq (llama-3.3-70b-versatile), Google Gemini (gemini-2.5-flash-lite), Perplexity (sonar-pro), Anthropic Claude (claude-sonnet-4)
          </li>
        </ul>

        <h3>Processing Pipeline</h3>
        <div class="subsection">
          <strong>Stage 1: PDF Upload & Analysis</strong>
          <ul>
            <li>File loaded into browser memory using FileReader API</li>
            <li>PDF.js parses document structure and extracts metadata</li>
            <li>Total page count, outline, and document properties determined</li>
          </ul>
        </div>

        <div class="subsection">
          <strong>Stage 2: Page-by-Page Extraction</strong>
          <ul>
            <li>Text extraction using page.getTextContent() for each page</li>
            <li>Image detection via operator list analysis</li>
            <li>Page classification: TEXT, IMAGE_ONLY, or MIXED</li>
          </ul>
        </div>

        <div class="subsection">
          <strong>Stage 3: Image Processing (if applicable)</strong>
          <ul>
            <li>Image-only pages rendered to PNG at 2x scale</li>
            <li>Images sent to Gemini API for detailed descriptions</li>
            <li>AI-generated descriptions stored as searchable text</li>
          </ul>
        </div>

        <div class="subsection">
          <strong>Stage 4: Content Normalization</strong>
          <ul>
            <li>Text and image descriptions merged into unified page array</li>
            <li>Table detection and extraction with row/column integrity</li>
            <li>Section heading identification using regex patterns</li>
          </ul>
        </div>

        <div class="subsection">
          <strong>Stage 5: Smart Chunking</strong>
          <ul>
            <li>Content split at sentence boundaries (never mid-word)</li>
            <li>Target chunk size: 800 characters; max: 1200 characters</li>
            <li>Metadata attached: documentId, sectionTitle, pageStart/End</li>
          </ul>
        </div>

        <div class="subsection">
          <strong>Stage 6: IndexedDB Storage</strong>
          <ul>
            <li>Documents, sections, chunks, tables, and images stored in separate stores</li>
            <li>Indexed by documentId for fast retrieval</li>
            <li>Status updated to "indexed" when complete</li>
          </ul>
        </div>

        <h3>Search & Retrieval</h3>
        <ul>
          <li>
            <strong>Keyword Search:</strong> Term frequency scoring with exact match bonus and partial match support
          </li>
          <li>
            <strong>Chunk Retrieval:</strong> Top-k chunks retrieved based on relevance score (typically k=5)
          </li>
          <li>
            <strong>Context Building:</strong> Retrieved chunks formatted with section titles and page references
          </li>
          <li>
            <strong>AI Query:</strong> Context sent to selected AI provider with user question
          </li>
          <li>
            <strong>Citation Display:</strong> Responses shown with inline page citations for verification
          </li>
        </ul>
      </section>

      <!-- CHALLENGES & SOLUTIONS -->
      <section class="container">
        <h2>Challenges & Solutions</h2>

        <div class="challenge-box">
          <strong>Challenge:</strong> Making scanned PDFs and image content searchable without OCR backend
          <br /><br />
          <strong>Solution:</strong> Implemented AI-powered image description using Google Gemini. Image-only pages are rendered to PNG and sent to Gemini API, which generates detailed text descriptions. These descriptions are indexed as searchable text, making visual content fully queryable.
        </div>

        <div class="challenge-box">
          <strong>Challenge:</strong> Maintaining document structure and context during chunking
          <br /><br />
          <strong>Solution:</strong> Developed smart chunking algorithm that splits content at sentence boundaries while preserving section metadata. Each chunk carries documentId, sectionTitle, and page range, ensuring retrieved content maintains its original context when displayed to users.
        </div>

        <div class="challenge-box">
          <strong>Challenge:</strong> Supporting multiple AI providers with different API formats
          <br /><br />
          <strong>Solution:</strong> Created unified API client with provider-specific adapters. Each provider (Groq, Gemini, Perplexity, Anthropic) implements a consistent interface, allowing seamless switching while handling provider-specific authentication, rate limits, and response formats.
        </div>

        <div class="challenge-box">
          <strong>Challenge:</strong> Ensuring privacy while leveraging AI capabilities
          <br /><br />
          <strong>Solution:</strong> Adopted local-first architecture with 100% client-side processing. Documents are stored in IndexedDB and never uploaded to servers. AI providers receive only necessary data (image blobs for description, text chunks for Q&A), and users provide their own API keys for complete control.
        </div>

        <div class="challenge-box">
          <strong>Challenge:</strong> Handling large PDFs without performance degradation
          <br /><br />
          <strong>Solution:</strong> Implemented progressive processing with visual progress indicators. Pages are processed in batches, images are analyzed in parallel (max 3 concurrent), and IndexedDB transactions are batched for efficiency. Large documents are handled incrementally to prevent memory issues.
        </div>
      </section>

      <!-- PROJECT STRUCTURE -->
      <section class="container">
        <h2>Project Structure</h2>

        <div class="subsection">
          <strong>Frontend Components</strong>
          <ul>
            <li><strong>/components/ui:</strong> shadcn/ui base components (Button, Card, Dialog, Tabs, etc.)</li>
            <li><strong>/components/Header.tsx:</strong> App header with navigation and settings access</li>
            <li><strong>/components/PDFViewer.tsx:</strong> Document viewer with tabs for Content, Tables, and Images</li>
            <li><strong>/components/ChatInterface.tsx:</strong> Q&A chat panel with provider selection</li>
            <li><strong>/components/DocumentLibrary.tsx:</strong> Document list and management UI</li>
            <li><strong>/components/APISettingsModal.tsx:</strong> API key configuration per provider</li>
          </ul>
        </div>

        <div class="subsection">
          <strong>Core Libraries</strong>
          <ul>
            <li><strong>pdfProcessor.ts:</strong> Orchestrates PDF ingestion, text extraction, image detection, and chunking</li>
            <li><strong>textChunker.ts:</strong> Splits content at sentence boundaries with metadata preservation</li>
            <li><strong>imageExtractor.ts:</strong> Detects image-only pages and renders them to PNG blobs</li>
            <li><strong>apiClient.ts:</strong> Unified interface for all AI providers (Groq, Gemini, Perplexity, Anthropic)</li>
            <li><strong>vectorSearch.ts:</strong> Keyword search and chunk retrieval with relevance scoring</li>
            <li><strong>db.ts:</strong> IndexedDB wrapper using idb library for CRUD operations</li>
          </ul>
        </div>

        <div class="subsection">
          <strong>State Management (Custom Hooks)</strong>
          <ul>
            <li><strong>useAPIKeys:</strong> Load, save, and validate API keys from IndexedDB</li>
            <li><strong>useChat:</strong> Manage chat messages, send queries, handle AI responses</li>
            <li><strong>useDocuments:</strong> CRUD operations for documents in IndexedDB</li>
          </ul>
        </div>

        <div class="subsection">
          <strong>IndexedDB Schema</strong>
          <ul>
            <li><strong>documents:</strong> Document metadata (id, title, pageCount, wordCount, status)</li>
            <li><strong>sections:</strong> Extracted sections with page ranges and content</li>
            <li><strong>chunks:</strong> Text chunks with metadata for retrieval</li>
            <li><strong>tables:</strong> Extracted tables with row/column data</li>
            <li><strong>images:</strong> Image metadata and AI-generated descriptions</li>
            <li><strong>chatHistory:</strong> Conversation history per document per provider</li>
            <li><strong>apiSettings:</strong> API keys for each provider</li>
          </ul>
        </div>
      </section>

      <!-- LEARNING OUTCOMES -->
      <section class="container">
        <h2>Learning Outcomes</h2>

        <h3>Technical Skills Developed</h3>
        <ul>
          <li>
            <strong>Client-Side PDF Processing:</strong> Mastered PDF.js for text extraction, page rendering, and operator list analysis for image detection
          </li>
          <li>
            <strong>IndexedDB Management:</strong> Implemented complex database schema with multi-store transactions and efficient indexing strategies
          </li>
          <li>
            <strong>AI Provider Integration:</strong> Built unified API client supporting multiple providers with different authentication methods and response formats
          </li>
          <li>
            <strong>Natural Language Processing:</strong> Developed chunking algorithms that preserve semantic coherence and document structure
          </li>
          <li>
            <strong>Privacy-First Design:</strong> Architected system with zero server dependencies and complete user data control
          </li>
          <li>
            <strong>React Advanced Patterns:</strong> Implemented custom hooks for state management, memoization for performance, and component composition for reusability
          </li>
        </ul>

        <h3>Enterprise Software Principles</h3>
        <ul>
          <li>
            <strong>Document Intelligence:</strong> Understanding how to transform unstructured PDFs into queryable knowledge bases
          </li>
          <li>
            <strong>Scalable Architecture:</strong> Designing systems that handle large documents (500+ pages) without performance degradation
          </li>
          <li>
            <strong>Error Handling:</strong> Graceful degradation when AI services fail, with clear user feedback and fallback behaviors
          </li>
          <li>
            <strong>User Experience:</strong> Progressive processing indicators, intuitive UI for complex operations, and clear API configuration workflows
          </li>
        </ul>

        <h3>Intel Unnati Program Insights</h3>
        <ul>
          <li>
            <strong>Industry Best Practices:</strong> Applied enterprise-grade architecture patterns learned from Intel Unnati curriculum
          </li>
          <li>
            <strong>Real-World Problem Solving:</strong> Addressed genuine organizational challenges in document management and knowledge retrieval
          </li>
          <li>
            <strong>Technology Integration:</strong> Gained experience integrating multiple AI providers and managing their distinct capabilities
          </li>
          <li>
            <strong>Quality Assurance:</strong> Implemented comprehensive validation, testing strategies, and edge case handling
          </li>
        </ul>
      </section>

      <!-- PERFORMANCE METRICS -->
      <section class="container">
        <h2>Performance Metrics</h2>

        <div class="subsection">
          <strong>Processing Speed</strong>
          <ul>
            <li>Text-only PDF (50 pages): 15-30 seconds</li>
            <li>Mixed content PDF (50 pages): 30-60 seconds</li>
            <li>Image-only PDF (50 pages): 2-5 minutes (dependent on AI API latency)</li>
          </ul>
        </div>

        <div class="subsection">
          <strong>Storage Efficiency</strong>
          <ul>
            <li>Text-only documents: ~1000 documents (100 pages each) in typical browser storage</li>
            <li>Mixed content: ~500 documents</li>
            <li>Chunk size optimization: 800 characters target, 1200 max (optimal for semantic coherence)</li>
          </ul>
        </div>

        <div class="subsection">
          <strong>Search Performance</strong>
          <ul>
            <li>Keyword search: <100ms for documents with 5000+ chunks</li>
            <li>Context retrieval: Top-5 chunks retrieved in <50ms</li>
            <li>AI response time: 1-3 seconds (Groq), 2-5 seconds (Claude/Perplexity)</li>
          </ul>
        </div>
      </section>

      <!-- FUTURE ENHANCEMENTS -->
      <section class="container">
        <h2>Future Enhancements</h2>

        <h3>Advanced Features</h3>
        <ul>
          <li>Vector embeddings for true semantic search using cosine similarity</li>
          <li>Cross-document search to query across entire document library</li>
          <li>Document comparison and diff analysis</li>
          <li>Annotation and highlighting with collaborative features</li>
          <li>Export to Markdown, JSON, or CSV formats</li>
        </ul>

        <h3>AI Capabilities</h3>
        <ul>
          <li>Fine-tuned models for domain-specific documents (legal, medical, technical)</li>
          <li>Multi-language OCR support for international documents</li>
          <li>Automated summarization and key insight extraction</li>
          <li>Knowledge graph generation from document relationships</li>
        </ul>

        <h3>Enterprise Features</h3>
        <ul>
          <li>Team collaboration with shared document libraries</li>
          <li>Role-based access control for sensitive documents</li>
          <li>Audit logs for document access and queries</li>
          <li>Integration with enterprise document management systems</li>
          <li>Custom API endpoints for workflow automation</li>
        </ul>
      </section>

      <!-- LINKS -->
      <div class="links-section">
        <h2 style="border: none; margin-bottom: 20px">Links & Resources</h2>
        <a
          href="https://github.com/Illusory-Warden/intelliread"
          target="_blank"
          >View GitHub Repository</a
        >
        <a href="https://intelliread-five.vercel.app" target="_blank">Live Demo</a>
        <a href="https://github.com/Illusory-Warden" target="_blank"
          >GitHub Profile</a
        >
      </div>

      <!-- BACK TO PORTFOLIO -->
      <div style="text-align: center; margin: 40px 0">
        <a href="index.html" class="back-link">‚Üê Back to Portfolio</a>
      </div>
    </div>

    <!-- GO TO TOP BUTTON -->
    <button id="goTopBtn" onclick="scrollToTop()">‚Üë Top</button>

    <script>
      // DARK MODE FUNCTIONALITY
      function toggleTheme() {
        const html = document.documentElement;
        const currentTheme = html.getAttribute("data-theme");
        const newTheme = currentTheme === "dark" ? "light" : "dark";
        const themeIcon = document.getElementById("themeIcon");

        html.setAttribute("data-theme", newTheme);
        localStorage.setItem("theme", newTheme);

        themeIcon.textContent = newTheme === "dark" ? "‚òÄÔ∏è" : "üåô";
      }

      // Load saved theme on page load
      function loadTheme() {
        const savedTheme = localStorage.getItem("theme") || "light";
        const themeIcon = document.getElementById("themeIcon");

        document.documentElement.setAttribute("data-theme", savedTheme);
        themeIcon.textContent = savedTheme === "dark" ? "‚òÄÔ∏è" : "üåô";
      }

      // SCROLL ANIMATION
      function animateOnScroll() {
        const containers = document.querySelectorAll(".container");

        containers.forEach((container) => {
          const containerTop = container.getBoundingClientRect().top;
          const containerBottom = container.getBoundingClientRect().bottom;
          const windowHeight = window.innerHeight;

          if (containerTop < windowHeight * 0.8 && containerBottom > 0) {
            container.classList.add("visible");
          }
        });
      }

      // GO TO TOP BUTTON
      window.onscroll = function () {
        animateOnScroll();

        const btn = document.getElementById("goTopBtn");
        if (
          document.body.scrollTop > 200 ||
          document.documentElement.scrollTop > 200
        ) {
          btn.style.display = "block";
        } else {
          btn.style.display = "none";
        }
      };

      function scrollToTop() {
        window.scrollTo({
          top: 0,
          behavior: "smooth",
        });
      }

      // Run on page load
      window.addEventListener("load", function () {
        loadTheme();
        animateOnScroll();
      });
    </script>
  </body>
</html>
